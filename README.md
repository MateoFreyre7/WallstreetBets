# WallstreetBets
Overview
	After the recent GameStop Stock story, I was interested in seeing if I could pinpoint what the next stock was that the WallStreetBets Reddit community was going to rally behind. After studying this subreddit channel, I discovered a daily discussion section where many users posted what stocks they were thinking of buying or what they had already. Due to the daily cadence of posts submitted on this topic, I determined that I could aggregate data from the post’s comment section and filter through the data to extract the stocks that are mentioned within. The tools I used for this data extraction, cleaning, and analysis consist of Python libraries including Pandas, Numpy, Json, and PRAW. I also used a list of all US Stock Symbols to check for valid stocks from this Github repository: https://github.com/rreichel3/US-Stock-Symbols .

Part 1: Data Extraction
	For data extraction on the project I chose to work with the API wrapper PRAW (Python Reddit API Wrapper). While using the PRAW library required more set up steps than other API solutions, involving creating and API key and ID, it ultimately exposed more Reddit API functionality that allowed the access of an entire comment structure within a Reddit submission. I leveraged this to pull all the top level comments made on the top most ‘hot’ submission thread on the WallStreetBets subreddit, which is always a daily discussion post about what users are looking to buy or rally behind on the current date. 
	The process of extraction begins with establishing a ‘reddit’ object using PRAW, which takes API credentials as input for the constructor. This object allows the querying of a given subreddit, which in turn grants the ability to find a submission and its associated comment structure (see lines 23 through 36). For this write up, I decided to only pull in a subset of the top level comments as a sample data set because the tree-like structure of the comments lead to long data extraction times, and for the purposes of this quick analysis, the top level comments would generally be responding to the main topic of the subreddit submission. The submission object has an iterable class variable (comments: a list of comment objects) that I iterated on to extract the core data of the analysis, the comment body. Finally, this list of comment bodies is populated into a pandas data frame on line 39.

Part 2: Data Munging
	The data cleaning portion of the project began with the removal of emojis using the following regex pattern: [^\w\s#@/:%.,_-].This first step was helpful as there were some stock symbols that were either surrounded by or near to some emojis. In a similar follow up step, I removed special characters using the following regex: \n|,|\?|\!|\$. This was helpful for similar reasons, but I wanted to point out that I decided not to remove the ‘.’ character as I did see some pricing data that I might be able to use in a future iteration of the project. 
	The next step was interesting as I needed to pull in data from the all_tickers.txt file, which contained all known US stock symbols, and join the data together to craft a regex pattern to find valid stock symbols. Line 16 through 20 demonstrates how I performed this operation and line 49 shows how I used it to parse out stock symbols from each row of comment data. I chose this approach simply because of how powerful and efficient regex is at parsing out specific string data. At this stage it isn’t 100% perfect because there are some cases where comments contain capital letters that are not meant to be stock symbols, but this is a future enhancement that is touched on in the Further Enhancements/Considerations section below. Furthermore, given the results, this is a margin of error that can be easily managed in the analysis

Part 3: Analysis
	This part of the project didn’t require too much work in terms of aggregation as the value_counts() method on line 49 did the summations of stock symbol occurrences already. I decided to filter out any stock symbols that had less than 50 as those weren’t significant enough to show on the final plot. Also for the sample set, it brought the final results to a clean top 3 stock occurrences. I then sorted the stock counts in a descending arrangement and leveraged the pd.DataFrame.plot() method to put together the necessary elements for the plot. This is built on top of matplotlib, which I needed to import to actually get the plot to show with the code on line 63. For the sample set of June 04, 2021, the final results showed that the Black Berry, Intelsat, and AMC Entertainment Holdings Inc. are the top 3 stocks that are being talked about in the Wallstreetbets subreddit. There is only one issue with this final plot, which is simply that the redditors were not actually talking about Intelsat, but were simply using a capital ‘I’ character a lot. For this reason we can likely remove this stock symbol from the final data set, but to further strengthen the data collection to avoid this issue, some context from the surrounding text can be taken to determine if the stock or the character is being used. For this analysis it is easy to pick out, but in the future, it can be helpful to automate this process as there are many different kinds of stocks that use common English words (such as LOVE).
